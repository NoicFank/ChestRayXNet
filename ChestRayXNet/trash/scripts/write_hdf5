# import h5py, os
# import caffe
# import numpy as np
#
# def write_hdf5(txt_path, image_size, hdf5_path):
#     SIZE = image_size # fixed size to all images
#     with open(txt_path, 'r' ) as T :
#         lines = T.readlines()
#         # If you do not have enough memory split data into
#         # multiple batches and generate multiple separate h5 files
#     X = np.zeros( (len(lines), 3, SIZE, SIZE), dtype='f4' )
#     y = np.zeros( (len(lines),1), dtype='f4' )
#     for i,l in enumerate(lines):
#         sp = l.split(' ')
#         img = caffe.io.load_image( sp[0] )
#         img = caffe.io.resize( img, (SIZE, SIZE, 3) ) # resize to fixed size
#         # you may apply other input transformations here...
#         # Note that the transformation should take img from size-by-size-by-3 and transpose it to 3-by-size-by-size
#         # for example
#         # transposed_img = img.transpose((2,0,1))[::-1,:,:] # RGB->BGR
#         X[i] = transposed_img
#         y[i] = float(sp[1])
#     with h5py.File('train.h5','w') as H:
#         H.create_dataset('X', data=X ) # note the name X given to the dataset!
#         H.create_dataset('y', data=y ) # note the name y given to the dataset!
#     with open(hdf5_path,'w') as L:
#         L.write('train.h5' ) # list all h5 files you are going to use
#
# if __name__ == '__main__':
#     txt_path =
#     hdf5_path =
#     image_size = 224